{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417a9e80-e1be-4db4-bfa5-831570a39fe3",
   "metadata": {},
   "source": [
    "# HF Transformers Core Model：Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a0774e0219d9231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T01:43:24.380901Z",
     "start_time": "2024-07-08T01:43:24.363385Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import logging\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置transformers库的日志级别为ERROR\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859d2d5c3a17a",
   "metadata": {},
   "source": [
    "## Natural Language Processing(NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5f632f28c6c4c",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9684ec5f-9460-4876-9883-69380eacb0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T01:07:44.779584Z",
     "start_time": "2024-07-08T01:07:43.313463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english:\n",
      "\t{'label': 'NEGATIVE', 'score': 0.9995032548904419}\n",
      "\t{'label': 'NEGATIVE', 'score': 0.9984821677207947}\n",
      "\t{'label': 'POSITIVE', 'score': 0.9961802959442139}\n",
      "\t{'label': 'NEGATIVE', 'score': 0.8957217335700989}\n",
      "\t{'label': 'NEGATIVE', 'score': 0.9238731265068054}\n",
      "\t{'label': 'NEGATIVE', 'score': 0.8578692674636841}\n",
      "lxyuan/distilbert-base-multilingual-cased-sentiments-student:\n",
      "\t{'label': 'negative', 'score': 0.7824518084526062}\n",
      "\t{'label': 'negative', 'score': 0.37749963998794556}\n",
      "\t{'label': 'positive', 'score': 0.7639099359512329}\n",
      "\t{'label': 'negative', 'score': 0.6657698154449463}\n",
      "\t{'label': 'neutral', 'score': 0.6030055284500122}\n",
      "\t{'label': 'positive', 'score': 0.9461327791213989}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "]\n",
    "texts = [\n",
    "    \"Today Shanghai is really cold.\",\n",
    "    \"I think the taste of the garlic mashed pork in this store is average.\",\n",
    "    \"You learn things really quickly. You understand the theory class as soon as it is taught.\",\n",
    "    \"今儿上海可真冷啊\",\n",
    "    \"我觉得这家店蒜泥白肉的味道一般\",\n",
    "    \"你学东西真的好快，理论课一讲就明白了\"\n",
    "]\n",
    "pipes = [pipeline(task=\"sentiment-analysis\",model=model) for model in models]\n",
    "for pipe in pipes:\n",
    "    print(f\"{pipe.model.name_or_path}:\",*pipe(texts), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686758b-d7f7-4df9-889d-e63af47a138a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d5a27fe-87d0-45fc-a31a-9a8db23e290a",
   "metadata": {},
   "source": [
    "### Token Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f1ed125-f9ed-42d9-b102-dbc3172baefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T02:44:01.275221Z",
     "start_time": "2024-07-08T02:44:01.256442Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    \"dslim/bert-base-NER\"\n",
    "]\n",
    "# 推理函数\n",
    "def classifier(text,grouped=False):\n",
    "    classifiers = [pipeline(task=\"ner\",model=model,grouped_entities=grouped) for model in models]\n",
    "    for classifier in classifiers:\n",
    "        preds = classifier(text)\n",
    "        print(f\"{classifier.model.name_or_path}:\",*preds, sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68bab77c-0fe6-4781-b978-02d56829db33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T02:44:06.645120Z",
     "start_time": "2024-07-08T02:44:04.269594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbmdz/bert-large-cased-finetuned-conll03-english:\n",
      "\t{'entity': 'I-ORG', 'score': 0.9967675, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "\t{'entity': 'I-ORG', 'score': 0.92930275, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "\t{'entity': 'I-ORG', 'score': 0.9763208, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "\t{'entity': 'I-MISC', 'score': 0.99828726, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "\t{'entity': 'I-LOC', 'score': 0.99896204, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "\t{'entity': 'I-LOC', 'score': 0.9986792, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "\t{'entity': 'I-LOC', 'score': 0.9992418, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n",
      "dslim/bert-base-NER:\n",
      "\t{'entity': 'B-ORG', 'score': 0.8935039, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "\t{'entity': 'I-ORG', 'score': 0.91499877, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "\t{'entity': 'I-ORG', 'score': 0.97772026, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "\t{'entity': 'B-MISC', 'score': 0.9996295, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "\t{'entity': 'B-LOC', 'score': 0.99948114, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "\t{'entity': 'I-LOC', 'score': 0.9994023, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "\t{'entity': 'I-LOC', 'score': 0.9995912, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b441191-6156-44b8-a323-db461ad06efb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T02:44:36.702465Z",
     "start_time": "2024-07-08T02:44:34.902205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbmdz/bert-large-cased-finetuned-conll03-english:\n",
      "\t{'entity_group': 'ORG', 'score': 0.9674637, 'word': 'Hugging Face', 'start': 0, 'end': 12}\n",
      "\t{'entity_group': 'MISC', 'score': 0.99828726, 'word': 'French', 'start': 18, 'end': 24}\n",
      "\t{'entity_group': 'LOC', 'score': 0.99896103, 'word': 'New York City', 'start': 42, 'end': 55}\n",
      "dslim/bert-base-NER:\n",
      "\t{'entity_group': 'ORG', 'score': 0.928741, 'word': 'Hugging Face', 'start': 0, 'end': 12}\n",
      "\t{'entity_group': 'MISC', 'score': 0.9996295, 'word': 'French', 'start': 18, 'end': 24}\n",
      "\t{'entity_group': 'LOC', 'score': 0.9994915, 'word': 'New York City', 'start': 42, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "classifier(\"Hugging Face is a French company based in New York City.\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7736791b-9585-4534-9efe-3fae3b7b6ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "369dda97-bd1a-4cb0-9636-47c2308c6289",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5281b0b-6b57-4884-92e1-cc2677987360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T02:38:55.482870Z",
     "start_time": "2024-07-08T02:38:54.322453Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"distilbert/distilbert-base-cased-distilled-squad\",\n",
    "    \"deepset/roberta-base-squad2\"\n",
    "]\n",
    "question_answerers = [{'model':model, 'pipe':pipeline(task=\"question-answering\",model=model)} for model in models]\n",
    "# 推理函数\n",
    "def questions(question,context):\n",
    "    for item in question_answerers:\n",
    "        model=item['model']\n",
    "        pipe=item['pipe']\n",
    "        pred = pipe(question=question, context=context)\n",
    "        print(f\"{model}:\\n\\t{pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca674a51-30a4-4dea-a443-e428925e990f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T02:38:57.460093Z",
     "start_time": "2024-07-08T02:38:57.382758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert/distilbert-base-cased-distilled-squad:\n",
      "\t{'score': 0.9327335953712463, 'start': 30, 'end': 54, 'answer': 'huggingface/transformers'}\n",
      "deepset/roberta-base-squad2:\n",
      "\t{'score': 0.906841516494751, 'start': 30, 'end': 54, 'answer': 'huggingface/transformers'}\n"
     ]
    }
   ],
   "source": [
    "questions(\n",
    "    \"What is the name of the repository?\",\n",
    "    \"The name of the repository is huggingface/transformers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2158feb-a528-410a-aabf-f3bd7f2726c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T02:39:00.158559Z",
     "start_time": "2024-07-08T02:39:00.067508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert/distilbert-base-cased-distilled-squad:\n",
      "\t{'score': 0.9458329677581787, 'start': 115, 'end': 122, 'answer': 'Beijing'}\n",
      "deepset/roberta-base-squad2:\n",
      "\t{'score': 0.7503766417503357, 'start': 115, 'end': 122, 'answer': 'Beijing'}\n"
     ]
    }
   ],
   "source": [
    "questions(\n",
    "    \"What is the capital of China?\", \n",
    "    \"On 1 October 1949, CCP Chairman Mao Zedong formally proclaimed the People's Republic of China in Tiananmen Square, Beijing.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd7483-99a5-4f2a-894c-13cf5a3b71b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d995cb85-ab8f-4b28-9413-1a83fa3e4c4d",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "86508667b20d4e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:01:34.255966Z",
     "start_time": "2024-07-08T03:01:30.013025Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"google-t5/t5-base\",\n",
    "    \"facebook/bart-large-cnn\"\n",
    "]\n",
    "pipes = [{'model':model, 'pipe':pipeline(task=\"summarization\",model=model,min_length=8,max_length=32)} for model in models]\n",
    "# 推理函数\n",
    "def summarizer(text):\n",
    "    for item in pipes:\n",
    "        model=item['model']\n",
    "        pipe=item['pipe']\n",
    "        pred = pipe(text)\n",
    "        print(f\"{model}:\\n\\t{pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c760bbf-2ae4-4f84-bd5e-32c30ee6bd78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:02:01.839654Z",
     "start_time": "2024-07-08T03:01:58.259191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-t5/t5-base:\n",
      "\t[{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decode'}]\n",
      "facebook/bart-large-cnn:\n",
      "\t[{'summary_text': 'The Transformer is the first sequence transduction model based entirely on attention. It replaces the recurrent layers most commonly used in encoder-decoder'}]\n"
     ]
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b50ff52b-e61e-40cd-ab66-a591dc0c3b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:02:12.341453Z",
     "start_time": "2024-07-08T03:02:08.422243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-t5/t5-base:\n",
      "\t[{'summary_text': 'large language models (LLMs) are very large deep learning models pre-trained on vast amounts of data . transformers are capable of un'}]\n",
      "facebook/bart-large-cnn:\n",
      "\t[{'summary_text': 'Transformers are a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. Unlike earlier recurrent neural'}]\n"
     ]
    }
   ],
   "source": [
    "summarizer(\n",
    "    '''\n",
    "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data. \n",
    "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. \n",
    "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
    "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning. \n",
    "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
    "    Unlike earlier recurrent neural networks (RNN) that sequentially process inputs, transformers process entire sequences in parallel. \n",
    "    This allows the data scientists to use GPUs for training transformer-based LLMs, significantly reducing the training time.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7ecaf45ec4f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72315144-7fae-4848-af79-a70e428b2416",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eba50f841aa167",
   "metadata": {},
   "source": [
    "### Audio classification"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:15:20.081025Z",
     "start_time": "2024-07-08T03:15:17.857447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"superb/hubert-base-superb-er\",\n",
    "    \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "]\n",
    "pipes = [{'model':model, 'pipe':pipeline(task=\"audio-classification\",model=model)} for model in models]\n",
    "# 推理函数\n",
    "def classifier(text):\n",
    "    for item in pipes:\n",
    "        model=item['model']\n",
    "        pipe=item['pipe']\n",
    "        preds = pipe(text)\n",
    "        preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "        print(f\"{model}:\",*preds, sep=\"\\n\\t\")"
   ],
   "id": "692562ae969abda7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:15:28.191396Z",
     "start_time": "2024-07-08T03:15:24.542539Z"
    }
   },
   "cell_type": "code",
   "source": "classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")",
   "id": "2fcf7c7e4ca66774",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superb/hubert-base-superb-er:\n",
      "\t{'score': 0.4532, 'label': 'hap'}\n",
      "\t{'score': 0.3622, 'label': 'sad'}\n",
      "\t{'score': 0.0943, 'label': 'neu'}\n",
      "\t{'score': 0.0903, 'label': 'ang'}\n",
      "MIT/ast-finetuned-audioset-10-10-0.4593:\n",
      "\t{'score': 0.4208, 'label': 'Speech'}\n",
      "\t{'score': 0.1793, 'label': 'Rain on surface'}\n",
      "\t{'score': 0.1301, 'label': 'Rain'}\n",
      "\t{'score': 0.096, 'label': 'Raindrop'}\n",
      "\t{'score': 0.0578, 'label': 'Music'}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:15:39.784373Z",
     "start_time": "2024-07-08T03:15:37.826630Z"
    }
   },
   "cell_type": "code",
   "source": "classifier(\"data/audio/mlk.flac\")",
   "id": "430ac30daf8a1cbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superb/hubert-base-superb-er:\n",
      "\t{'score': 0.4532, 'label': 'hap'}\n",
      "\t{'score': 0.3622, 'label': 'sad'}\n",
      "\t{'score': 0.0943, 'label': 'neu'}\n",
      "\t{'score': 0.0903, 'label': 'ang'}\n",
      "MIT/ast-finetuned-audioset-10-10-0.4593:\n",
      "\t{'score': 0.4208, 'label': 'Speech'}\n",
      "\t{'score': 0.1793, 'label': 'Rain on surface'}\n",
      "\t{'score': 0.1301, 'label': 'Rain'}\n",
      "\t{'score': 0.096, 'label': 'Raindrop'}\n",
      "\t{'score': 0.0578, 'label': 'Music'}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "abedd9cd6af28ba5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Automatic speech recognition（ASR）",
   "id": "fee30f808be36722"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:21:54.891805Z",
     "start_time": "2024-07-08T03:21:52.255887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"openai/whisper-small\",\n",
    "    \"facebook/wav2vec2-base-960h\"\n",
    "]\n",
    "pipes = [{'model':model, 'pipe':pipeline(task=\"automatic-speech-recognition\",model=model)} for model in models]\n",
    "# 推理函数\n",
    "def recognition(text):\n",
    "    for item in pipes:\n",
    "        model=item['model']\n",
    "        pipe=item['pipe']\n",
    "        pred = pipe(text)\n",
    "        print(f\"{model}:\\n\\t{pred}\")"
   ],
   "id": "ba925a378a9a9ed5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:22:01.637336Z",
     "start_time": "2024-07-08T03:21:56.927134Z"
    }
   },
   "cell_type": "code",
   "source": "recognition(\"data/audio/mlk.flac\")",
   "id": "2ad0cb222da8b0ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/whisper-small:\n",
      "\t{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n",
      "facebook/wav2vec2-base-960h:\n",
      "\t{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "db036611c7d241c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Computer Vision",
   "id": "9f5400e72f1c9b33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Image Classificaiton",
   "id": "d7fca6d9de0b064c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:31:44.599685Z",
     "start_time": "2024-07-08T03:31:42.366251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    \"microsoft/resnet-50\"\n",
    "]\n",
    "pipes = [{'model':model, 'pipe':pipeline(task=\"image-classification\",model=model)} for model in models]\n",
    "# 推理函数\n",
    "def classifier(text):\n",
    "    for item in pipes:\n",
    "        model=item['model']\n",
    "        pipe=item['pipe']\n",
    "        preds = pipe(text)\n",
    "        preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "        print(f\"{model}:\",*preds, sep=\"\\n\\t\")"
   ],
   "id": "6841e31de312815e",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:31:48.340612Z",
     "start_time": "2024-07-08T03:31:46.073079Z"
    }
   },
   "cell_type": "code",
   "source": "classifier(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\")",
   "id": "f159f2b2287f2d8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/vit-base-patch16-224:\n",
      "\t{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "\t{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "\t{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "\t{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "\t{'score': 0.0229, 'label': 'tiger cat'}\n",
      "microsoft/resnet-50:\n",
      "\t{'score': 0.5874, 'label': 'lynx, catamount'}\n",
      "\t{'score': 0.1289, 'label': 'tabby, tabby cat'}\n",
      "\t{'score': 0.075, 'label': 'marmot'}\n",
      "\t{'score': 0.0382, 'label': 'badger'}\n",
      "\t{'score': 0.0131, 'label': 'Egyptian cat'}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](data/image/cat-chonk.jpeg)",
   "id": "e3a3c59b54827327"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:31:54.743180Z",
     "start_time": "2024-07-08T03:31:54.515406Z"
    }
   },
   "cell_type": "code",
   "source": "classifier(\"data/image/cat-chonk.jpeg\")",
   "id": "a64e6729ba223cf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/vit-base-patch16-224:\n",
      "\t{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "\t{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "\t{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "\t{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "\t{'score': 0.0229, 'label': 'tiger cat'}\n",
      "microsoft/resnet-50:\n",
      "\t{'score': 0.5874, 'label': 'lynx, catamount'}\n",
      "\t{'score': 0.1289, 'label': 'tabby, tabby cat'}\n",
      "\t{'score': 0.075, 'label': 'marmot'}\n",
      "\t{'score': 0.0382, 'label': 'badger'}\n",
      "\t{'score': 0.0131, 'label': 'Egyptian cat'}\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](data/image/panda.jpg)",
   "id": "450441492c0b92a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T03:32:01.047696Z",
     "start_time": "2024-07-08T03:32:00.815534Z"
    }
   },
   "cell_type": "code",
   "source": "classifier(\"data/image/panda.jpg\")",
   "id": "75bb8a2b5f6f63b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/vit-base-patch16-224:\n",
      "\t{'score': 0.9962, 'label': 'giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca'}\n",
      "\t{'score': 0.0018, 'label': 'lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens'}\n",
      "\t{'score': 0.0002, 'label': 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus'}\n",
      "\t{'score': 0.0001, 'label': 'sloth bear, Melursus ursinus, Ursus ursinus'}\n",
      "\t{'score': 0.0001, 'label': 'brown bear, bruin, Ursus arctos'}\n",
      "microsoft/resnet-50:\n",
      "\t{'score': 0.9768, 'label': 'giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca'}\n",
      "\t{'score': 0.0088, 'label': 'indri, indris, Indri indri, Indri brevicaudatus'}\n",
      "\t{'score': 0.0004, 'label': 'groenendael'}\n",
      "\t{'score': 0.0003, 'label': 'Siberian husky'}\n",
      "\t{'score': 0.0002, 'label': 'malamute, malemute, Alaskan malamute'}\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea6e9be0105dc1bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Object Detection",
   "id": "49abfb4b40de4b48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T04:16:58.233918Z",
     "start_time": "2024-07-08T04:16:55.632817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models=[\n",
    "    \"facebook/detr-resnet-50\",\n",
    "    \"SenseTime/deformable-detr\"\n",
    "]\n",
    "pipes = [{'model':model, 'pipe':pipeline(task=\"object-detection\",model=model)} for model in models]\n",
    "# 推理函数\n",
    "def detector(text):\n",
    "    for item in pipes:\n",
    "        model=item['model']\n",
    "        pipe=item['pipe']\n",
    "        preds = pipe(text)\n",
    "        preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "        print(f\"{model}:\",*preds, sep=\"\\n\\t\")"
   ],
   "id": "8123ffd594f0fc6f",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T04:17:06.597086Z",
     "start_time": "2024-07-08T04:17:00.232895Z"
    }
   },
   "cell_type": "code",
   "source": "detector(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\")",
   "id": "bbdb8f066f400073",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook/detr-resnet-50:\n",
      "\t{'score': 0.9864, 'label': 'cat', 'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}\n",
      "SenseTime/deformable-detr:\n",
      "\t{'score': 0.8068, 'label': 'cat', 'box': {'xmin': 179, 'ymin': 154, 'xmax': 877, 'ymax': 595}}\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](data/image/cat_dog.jpg)",
   "id": "7d10b5539c30ecbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T04:17:27.318529Z",
     "start_time": "2024-07-08T04:17:22.950420Z"
    }
   },
   "cell_type": "code",
   "source": "detector(\"data/image/cat_dog.jpg\")",
   "id": "ad19ccadafddf2fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook/detr-resnet-50:\n",
      "\t{'score': 0.9985, 'label': 'cat', 'box': {'xmin': 78, 'ymin': 57, 'xmax': 309, 'ymax': 371}}\n",
      "\t{'score': 0.989, 'label': 'dog', 'box': {'xmin': 279, 'ymin': 20, 'xmax': 482, 'ymax': 416}}\n",
      "SenseTime/deformable-detr:\n",
      "\t{'score': 0.6333, 'label': 'cat', 'box': {'xmin': 78, 'ymin': 60, 'xmax': 309, 'ymax': 372}}\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972a843-8213-470a-bfa3-63faa4475b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
